# gpu config
accelerator: gpu
devices: [0,1,2,3,4]

# log config
log_dir: ./log
resume: null # if want to resume, specify ckpt path

# inference
ckpt_path: ./checkpoints/epoch=84-step=175499-pesq=1.36-utmos=1.98.ckpt
# dataset config
dataset_config:
  train_kwargs:
    batch_size: 32
    cut_duration: [5.0, 5.0]  # 5.0 seconds
    num_workers: 16  # dataloader workers
    prefetch: 32
    samples_per_epoch: 400000
    domain_weights_dict:
      speech: 2
      music: 1
      audio: 1
    audio_scp_path: # 一般音频训练数据
      - /AudioSet/audioset_train.scp
      - /WavCaps/wavcaps.scp
    music_scp_path: # 音乐训练数据
      - /music/free-music-archive-full/fma-f.scp
      - /music/musdb18hq/musdb18hq_train.scp
    speech_scp_base_dir: /voxbox
    speech_scp_path: # 语音训练数据
      - /voxbox/wav_scp/librispeech.scp
  val_kwargs:
    batch_size: 1
    num_workers: 1
    prefetch: 1
    cut_duration: [5.0, 5.0]  # 5.0 seconds
    samples_per_epoch: 1000
    speech_scp_path: /librispeech_test_clean.scp
    music_scp_path: /MUSDB18-HQ/musdb18hq_test_one_dir.scp
    audio_scp_path: /Audio_dataset/AudioSet/audioset_eval.scp
  test_kwargs:  #------测试模型重建性能
    batch_size: 1
    num_workers: 12
    prefetch: 1
    domain: audio
    #wav_scp_path: /musdb18hq_test_one_dir.scp
    #wav_scp_path: /audioset_eval.scp

# training config
# max_epochs: 200
# val_check_interval: 0.5  # validate every 0.5 epochs
max_steps: 1_000_000  # 0.5M steps 注意需要除以2
val_check_interval: 1_000  # validate every 2k steps
check_val_every_n_epoch: null  # validate based on the total training batches
limit_val_batches: 200  # 只用200个batch来验证
perceptual_start_step: 400_000

gradient_clip_val: 5.0
opt_gen:
  lr: 2.0e-4
opt_disc:
  lr: 2.0e-4
sch:
  warmup_steps: 0

encoder_config:
  channels: 1
  dimension: 512
  n_filters: 32
  n_residual_layers: 1
  ratios: [2, 4, 5, 8]
  causal: false
decoder_config:
  input_channels: 512
  dim: 768
  intermediate_dim: 2304
  convnext_layers: 12
  n_fft: 1280
  hop_length: 320  # np.prod(ratios)
  causal: false
# quantizer_config:
#   n_e: 4096
#   e_dim: 512
#   legacy: true
# quantizer_config:
#   num_quantizers: 1
#   dim: 512
#   codebook_size: 8192
#   codebook_dim: 8
#   threshold_ema_dead_code: 2
#   commitment: 0.25
#   weight_init: false
#   full_commit_loss: false
quantizer_config:
  dim: 512
  codebook_size: 4096
  num_quantizers: 1
  decay: 0.99
  kmeans_init: true
  kmeans_iters: 200
  threshold_ema_dead_code: 2


contrasive_criterion_config:
  encoder_embed_dim: 512
  final_dim: 256
  num_negatives: 30
  cross_sample_negatives: 0
  logit_temp: 0.1


