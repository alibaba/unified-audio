# inference
ckpt_path: ./checkpoints/hcode_1.5_adaptive_4+4.pt

# model architecture
encoder_config:
  ratios: [2, 4, 5, 8]   
  encoder:
    causal: false 
    n_residual_layers: 1
    norm: weight_norm
    pad_mode: reflect
    lstm: 6   
    dimension: 512         # 512*4
    channels: 1
    n_filters: 32         # 32*4
    ratios: [2, 4, 5, 8]
    activation: ELU     
    kernel_size: 7
    residual_kernel_size: 3
    last_kernel_size: 7
    dilation_base: 2
    true_skip: false
    compress: 2
    use_transformer: true 
  semantic_encoder:
    input_channels: 1024
    encode_channels: 1024
    out_channels: 512
    channel_ratios: [1, 1]
    strides: [2, 1]

decoder_config:
  decoder:
    input_channels: 1024     # 512*5
    dim: 1024
    intermediate_dim: 2304   # 1024*3
    # num_layers: 12
  semantic_decoder:
    code_dim: 512
    output_channels: 1024
    decode_channels: 1024
    channel_ratios: [1, 1]
    strides: [2, 1]


quantizer_config:
  quantizer:
    dim: 512
    codebook_size: 1024
    num_quantizers: 4
    decay: 0.99
    kmeans_init: true
    kmeans_iters: 50
    quantize_dropout: true

  semantic_quantizer:
    dim: 512
    codebook_size: 1024
    num_quantizers: 4
    decay: 0.99
    kmeans_init: true
    kmeans_iters: 50
    quantize_dropout: true

adaptive_config: 
  training: false
  use_similarity_alignment: true
  use_dynamic_similarity_threshold: false
  infer_using_dynamic_threshold: false
  similarity_threshold: 0.7
  similarity_threshold_lower: 0.7
  similarity_threshold_upper: 1.0
  max_tokens_per_group: 8
  manual_threshold: 0.6 # only for infering stage with fixed threshold 
  use_query_token_aggregator: true
  aggregators:
    semantic_aggregator:
      dim: 512
      in_out_dim: 512
      num_heads: 8
      num_layers: 32
      dim_feedforward: 2048
      causal: false
      use_mean_pooling_init: true
      context_frames: 16
    acoustic_aggregator:
      dim: 512
      in_out_dim: 512   # 512*4
      num_heads: 8
      num_layers: 32
      dim_feedforward: 2048
      causal: false
      use_mean_pooling_init: true
      context_frames: 16
  use_bottleneck_transformer: true
  transformer_kwargs:
    d_model: 1024                # transformer_dim
    num_heads: 8                 # transformer_num_heads
    num_layers: 32               # transformer_num_layers
    causal: false                # transformer_causal
    layer_scale: 0.01
    context: 16                  # transformer_context_frames, calculated context window
    conv_layout: true
    max_period: 10000
    gating: "none"
    norm: "layer_norm"
    positional_embedding: "rope"
    dim_feedforward: 2048        # transformer_dim_feedforward
    input_dimension: 1024        # latent_dim
    output_dimensions:           # 512 (latent_dim)
      - 1024